<pre>
Currently, this repository is still in its infancy.
Contributors are asked to focus on extending preliminary_word_list.
Please see more info below under "How can I contribute" question.
</pre>

==How can I contribute?==
Currently, this repository is still in its infancy. Until this repo gets enough traction, one should focus on languages based on the Latin alphabet. The prerequisite is to create ''preliminary_word_list'' which can be translated to all languages and then trimmed to the word lists in their final forms, with the use of the scripts this repo offers.

==Is there any roadmap? How can I add a word list for a new language?==
Again, this repo is still in its infancy. The work should progress as follows:
* finishing creation of the ''preliminary_word_list''
* for each language:
** translate ''preliminary_word_list''
** create a draft of the word list by extracting words fulfilling requirements; this can be automated using the script:
   <code>python3 scripts/create_word_list.py -l translated_preliminary_word_list</code>
** <p>manually polish the list. At the moment of writing, the ''preliminary_word_list'' consists of 1394 words. The script to extract a set of words fulfilling the requirements (with simply: ''/usr/bin/python3.6 scripts/create_word_list.py -l english_us'') produces a draft of list with 859 words. The longer the list, the higher the shrinkage. The shrinkage will vary across languages. There is no guarantee that ''preliminary_word_list'' of length ~5k or (let the imagination fly) even 100k will suffice to provide 2048 words or more. However, as part of the final polishing, one can add manually missing words. Adding just missing words is easier than creating all of them from scratch.</p>

==When can I expect language_x to be added?==
After the creation of [[wlip-0003/preliminary-word-lists/english_us|preliminary word list]] things should speed up.
However, the work on wlips is not meant to be done any under time pressure.
The lists should be released within reasonable periods.
However, as a prerequisite, at least a couple of them should be created to prove the approach is correct.
The work might need to be paused, some conclusions drawn and the approach readjusted.
They should be though rather of minor importance.

==Why it is allowed for the lists to share common words?==
Some people believe that duplicates across the lists should be forbidden.
They believe that it would allow recognizing a list using just one random word.
However, it would cause more problems than benefits.
Why? It is because:
* which words will be most likely duplicated? the ones which are the most common,
* with each new list, the task of choosing words will be harder and harder,
* <p>one should not recognize lists not by a single word, but by an industry-standard solution: using hashes (it is part of WLIP-0002 proposal). Thanks to it even multiple lists for a single language may coexist. For example, the current English list and hopefully a newer one, fulfilling new requirements,</p>
* <p>one should use it as an advantage - the more words shared across the lists, the easier to create them. Also, the number of commonly shared words should not be limited - the more the better.</p>
